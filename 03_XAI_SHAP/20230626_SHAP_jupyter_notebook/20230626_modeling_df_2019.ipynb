{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e1f8bf",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "* Use just one year (e.g. 2019)\n",
    "* Train on 70 %, test on 30 % of the data \n",
    "* Random forests (classification)\n",
    "\n",
    "* two classes\n",
    "* decrease class means > -10%\n",
    "* no change class is between -5 and 5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326e153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapenv Anaconda environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "\n",
    "# ML libraries \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SHAP values\n",
    "import shap\n",
    "#shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7616bf",
   "metadata": {},
   "source": [
    "# Load the modeling dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afb80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               x          y  NDVI_anomaly  agriculture_proximity      aspect  \\\n",
      "0      13.694817  53.463234     -5.224010             101.598724  168.056488   \n",
      "1      14.215839  53.391369     -4.695665             141.954056  166.101166   \n",
      "2      14.215839  53.382386     -6.167371             340.478790  160.925415   \n",
      "3      14.224823  53.382386    -12.489527             177.500885  137.270935   \n",
      "4      14.215839  53.373403     -8.321093             251.918365  155.945984   \n",
      "...          ...        ...           ...                    ...         ...   \n",
      "50963  13.883463  51.379143    -11.596499             364.639801  193.677811   \n",
      "50964  13.892446  51.379143    -17.068777             220.772079  213.901718   \n",
      "50965  13.901429  51.379143    -18.853287             198.778305  201.734650   \n",
      "50966  13.973294  51.379143    -11.722972             357.211304  136.366745   \n",
      "50967  13.703800  51.370160    -14.234449              64.125183  165.034775   \n",
      "\n",
      "       broadleaf_percentage  canopyheight   elevation  forest_proximity  \\\n",
      "0                  0.603314     19.391434   97.740540         67.239449   \n",
      "1                  0.149953     18.845116   15.861407         86.804245   \n",
      "2                  0.096443     23.794508   17.177540        128.644455   \n",
      "3                  0.159683     19.031954   14.218534         61.986855   \n",
      "4                  0.057754     21.656668   17.408154        125.104263   \n",
      "...                     ...           ...         ...               ...   \n",
      "50963              0.057157     25.146816  121.694084        179.882599   \n",
      "50964              0.124788     23.017693  122.201851        113.490257   \n",
      "50965              0.094708     20.214455  122.953598         76.428818   \n",
      "50966              0.006663     22.712748  139.370575        118.962395   \n",
      "50967              0.127199     20.886402  149.972595         32.338631   \n",
      "\n",
      "       groundwater_level  ...  SPEI_sameyear  SSM_sameyear  \\\n",
      "0              36.422783  ...      -0.913538     40.332726   \n",
      "1               5.470210  ...      -0.888533     50.603706   \n",
      "2               9.605913  ...      -0.893272     52.484608   \n",
      "3               6.756446  ...      -0.880789     47.255898   \n",
      "4              13.732240  ...      -0.884934     48.173389   \n",
      "...                  ...  ...            ...           ...   \n",
      "50963           7.175178  ...      -1.013399     65.503853   \n",
      "50964           7.379456  ...      -1.036419     63.501202   \n",
      "50965           6.580887  ...      -1.058506     59.010555   \n",
      "50966          13.135468  ...      -1.135887     58.753532   \n",
      "50967          41.140312  ...      -0.987508     41.423916   \n",
      "\n",
      "       SWI_100cm_sameyear  SWI_sameyear  ESI_1year  SMI_1year  SPEI_1year  \\\n",
      "0               50.058811     44.647263   0.596929   0.435959   -1.196411   \n",
      "1               56.151264     52.977642   0.634467   0.454932   -1.096218   \n",
      "2               56.905312     53.778286   0.598551   0.461681   -1.095755   \n",
      "3               56.073048     52.790947   0.582416   0.467806   -1.092443   \n",
      "4               55.502964     52.112804   0.582978   0.447080   -1.089536   \n",
      "...                   ...           ...        ...        ...         ...   \n",
      "50963           51.937523     47.018528   0.533109   0.277214   -0.271749   \n",
      "50964           54.454117     50.078003   0.493553   0.246074   -0.283945   \n",
      "50965           52.636932     47.748051   0.468304   0.231403   -0.292921   \n",
      "50966           50.979046     46.068127   0.617913   0.139471   -0.348668   \n",
      "50967           47.801109     36.430370   0.566822   0.224587   -0.141515   \n",
      "\n",
      "       SSM_1year  SWI_100cm_1year  SWI_1year  \n",
      "0      40.333015        54.566082  46.733868  \n",
      "1      46.626461        59.730282  53.019611  \n",
      "2      46.771858        60.314598  53.774075  \n",
      "3      45.909496        60.208996  53.490135  \n",
      "4      44.427063        59.666473  52.612869  \n",
      "...          ...              ...        ...  \n",
      "50963  60.697250        58.945820  59.104298  \n",
      "50964  61.085831        60.820618  60.990917  \n",
      "50965  59.061237        59.608376  59.898434  \n",
      "50966  59.808304        58.284199  58.753437  \n",
      "50967  49.606262        53.885521  55.351353  \n",
      "\n",
      "[50968 rows x 27 columns]\n",
      "(12281, 27)\n",
      "[2019]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataframe from a file \n",
    "df = pd.read_csv('D:/Stenka_Cliwac/Topic_1/04_PROCESSED_DATA/20230623_modeling_df/all/noNA/modeling_df_noNA.csv')\n",
    "# Rows: 50,968\n",
    "# Columns: 27\n",
    "\n",
    "# Keep the columns named \"x\" and \"y\" this time\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n",
    "# [50968 rows x 27 columns]\n",
    "\n",
    "# Subset to year 2019 \n",
    "\n",
    "df_2019 = df[df[\"Year_NDVI_anom\"] == 2019] # 12676 rows, 20 columns \n",
    "print(df_2019.shape) \n",
    "# (12281, 27)\n",
    "\n",
    "# Get the unique values in the \"Year_NDVI_anom\" column\n",
    "unique_years = df_2019['Year_NDVI_anom'].unique()\n",
    "\n",
    "# Print the unique years\n",
    "print(unique_years) # [2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797a907",
   "metadata": {},
   "source": [
    "# Create new classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d776f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_categories\n",
      "no_change         5217\n",
      "small_decrease    4470\n",
      "large_decrease    2491\n",
      "small_increase      80\n",
      "large_increase      23\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Define the thresholds and corresponding categories\n",
    "thresholds = [-np.inf, -10, -5, 5, 10, np.inf]\n",
    "categories = [\"large_decrease\", \"small_decrease\", \"no_change\", \"small_increase\", \"large_increase\"]\n",
    "\n",
    "# Create a new column \"NDVI_categories\" based on the classification\n",
    "df_2019[\"NDVI_categories\"] = pd.cut(df_2019[\"NDVI_anomaly\"], bins=thresholds, labels=categories, right=False)\n",
    "\n",
    "# number per category\n",
    "\n",
    "category_counts = df_2019[\"NDVI_categories\"].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "#NDVI_categories\n",
    "#no_change         5217\n",
    "#small_decrease    4470\n",
    "#large_decrease    2491\n",
    "#small_increase      80\n",
    "#large_increase      23\n",
    "#Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcedf4",
   "metadata": {},
   "source": [
    "# Remove increase classes\n",
    "\n",
    "* too few samples in the % increase categories\n",
    "* plus, my study is about why the forest suffers...\n",
    "* I am also removing the \"small_decrease\" class now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4db20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_change', 'large_decrease']\n",
      "Categories (5, object): ['large_decrease' < 'small_decrease' < 'no_change' < 'small_increase' < 'large_increase']\n",
      "NDVI_categories\n",
      "no_change         5217\n",
      "large_decrease    2491\n",
      "small_decrease       0\n",
      "small_increase       0\n",
      "large_increase       0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask for rows to be removed\n",
    "mask = (df_2019[\"NDVI_categories\"] == \"small_increase\") | (df_2019[\"NDVI_categories\"] == \"large_increase\") | (df_2019[\"NDVI_categories\"] == \"small_decrease\")\n",
    "\n",
    "# Apply the mask to the dataframe to remove the rows\n",
    "df_filtered = df_2019[~mask]\n",
    "\n",
    "# categories\n",
    "print(df_filtered[\"NDVI_categories\"].unique()) # ['no_change', 'large_decrease']\n",
    "\n",
    "print(df_filtered[\"NDVI_categories\"].value_counts())\n",
    "#NDVI_categories\n",
    "#no_change         5217\n",
    "#large_decrease    2491\n",
    "#small_decrease       0\n",
    "#small_increase       0\n",
    "#large_increase       0\n",
    "#Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b1b68",
   "metadata": {},
   "source": [
    "# Make sample sizes per class equal\n",
    "\n",
    "* less samples per category\n",
    "* 2000 to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c25bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_categories\n",
      "large_decrease    2000\n",
      "no_change         2000\n",
      "small_decrease       0\n",
      "small_increase       0\n",
      "large_increase       0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2000 to start with\n",
    "# Set the desired number of samples per category\n",
    "num_samples = 2000\n",
    "\n",
    "# Group the dataframe by the \"NDVI_categories\" column\n",
    "grouped = df_filtered.groupby(\"NDVI_categories\")\n",
    "\n",
    "# Create an empty list to store the sampled dataframes\n",
    "sampled_dfs = []\n",
    "\n",
    "# Iterate over each group\n",
    "for category, group in grouped:\n",
    "    # Check if the number of samples in the group is greater than the desired number\n",
    "    if len(group) > num_samples:\n",
    "        # Randomly sample the desired number of rows from the group\n",
    "        sampled_group = group.sample(n=num_samples, random_state=42)\n",
    "        # Add the sampled group to the list\n",
    "        sampled_dfs.append(sampled_group)\n",
    "    else:\n",
    "        # If the group has fewer samples than the desired number, add all rows to the list\n",
    "        sampled_dfs.append(group)\n",
    "\n",
    "# Concatenate the sampled dataframes back into a single dataframe\n",
    "df_sub_2019 = pd.concat(sampled_dfs)\n",
    "\n",
    "# Optional: Reset the index of the resulting dataframe\n",
    "df_sub_2019 = df_sub_2019.reset_index(drop=True)\n",
    "\n",
    "print(df_sub_2019[\"NDVI_categories\"].value_counts())\n",
    "# large_decrease    2000\n",
    "#no_change         2000\n",
    "#small_decrease       0\n",
    "#small_increase       0\n",
    "#large_increase       0\n",
    "#Name: NDVI_categories, dtype: int64\n",
    "\n",
    "# save it\n",
    "df_sub_2019.to_csv(\"D:/Stenka_Cliwac/Topic_1/04_PROCESSED_DATA/20230623_modeling_df/all/twoclass_subset/modeling_df_2class_2019.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
